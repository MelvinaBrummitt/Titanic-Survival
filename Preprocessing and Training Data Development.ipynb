{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7263ed52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the cleaned datasets\n",
    "train_df = pd.read_csv('cleaned_train.csv')\n",
    "test_df = pd.read_csv('cleaned_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "08fdaeee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass           0\n",
      "Sex_male         0\n",
      "Title_Miss       0\n",
      "Title_Mr         0\n",
      "Title_Mrs        0\n",
      "Title_Officer    0\n",
      "Title_Royalty    0\n",
      "Age              0\n",
      "Fare             1\n",
      "FamilySize       0\n",
      "Has_Cabin        0\n",
      "Embarked_Q       0\n",
      "Embarked_S       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the test dataset\n",
    "print(X_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f737cebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "features = ['Pclass', 'Sex_male', 'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Title_Officer', 'Title_Royalty', 'Age', 'Fare', 'FamilySize', 'Has_Cabin', 'Embarked_Q', 'Embarked_S']\n",
    "target = 'Survived'\n",
    "\n",
    "# Extract features and target from the training data\n",
    "X_train_full = train_df[features]\n",
    "y_train_full = train_df[target]\n",
    "\n",
    "# Extract features from the test data (no target)\n",
    "X_test = test_df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ce64d92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing for numeric and categorical features\n",
    "numeric_features = ['Age', 'Fare', 'FamilySize']\n",
    "categorical_features = ['Pclass', 'Sex_male', 'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Title_Officer', 'Title_Royalty', 'Embarked_Q', 'Embarked_S']\n",
    "\n",
    "# Create a ColumnTransformer to preprocess both numeric and categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', 'passthrough', categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Apply preprocessing to both training and test data\n",
    "X_train_processed = preprocessor.fit_transform(X_train_full)\n",
    "X_test_processed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ac0e041c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (712, 12)\n",
      "Validation set size: (179, 12)\n"
     ]
    }
   ],
   "source": [
    "# Split the training data into training and validation subsets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_processed, y_train_full, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training set size:\", X_train.shape)\n",
    "print(\"Validation set size:\", X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a79881c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy score: 0.8324022346368715\n",
      "Validation Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.85       105\n",
      "           1       0.78      0.82      0.80        74\n",
      "\n",
      "    accuracy                           0.83       179\n",
      "   macro avg       0.83      0.83      0.83       179\n",
      "weighted avg       0.83      0.83      0.83       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train a RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = model.predict(X_val)\n",
    "print(\"Validation Accuracy score:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"Validation Classification report:\\n\", classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "38a6bb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Define preprocessing for numeric and categorical features\n",
    "numeric_features = ['Age', 'Fare', 'FamilySize']\n",
    "categorical_features = ['Pclass', 'Sex_male', 'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Title_Officer', 'Title_Royalty', 'Embarked_Q', 'Embarked_S']\n",
    "\n",
    "# Create a ColumnTransformer with imputation and scaling\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='median')),  # Impute missing numeric values\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), numeric_features),\n",
    "        ('cat', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing categorical values\n",
    "            ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Apply preprocessing to both training and test data\n",
    "X_train_processed = preprocessor.fit_transform(X_train_full)\n",
    "X_test_processed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1cea848f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy score: 0.8268156424581006\n",
      "Validation Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85       105\n",
      "           1       0.77      0.82      0.80        74\n",
      "\n",
      "    accuracy                           0.83       179\n",
      "   macro avg       0.82      0.83      0.82       179\n",
      "weighted avg       0.83      0.83      0.83       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the training data into training and validation subsets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_processed, y_train_full, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train a RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = model.predict(X_val)\n",
    "print(\"Validation Accuracy score:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"Validation Classification report:\\n\", classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = model.predict(X_test_processed)\n",
    "\n",
    "# Create a DataFrame to hold predictions for submission\n",
    "submission_df = pd.DataFrame({'PassengerId': test_df['PassengerId'], 'Survived': y_test_pred})\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898be942",
   "metadata": {},
   "source": [
    "The dataset includes categorical data like passenger class, gender (coded as `Sex_male`), and titles (`Title_Miss`, `Title_Mr`, `Title_Mrs`, etc.). These categories were turned into numerical values so they can be used in the model. The dataset also has a mix of ranges. Categorical features are either 0 or 1. Numeric features like age and fare had different ranges but were standardized to make all values similar, helping the model work better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dffe4b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
